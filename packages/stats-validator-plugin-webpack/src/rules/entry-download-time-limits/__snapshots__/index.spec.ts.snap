// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`exclude entry object 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [
                Object {
                  "name": Object {
                    "content": "tw",
                    "flags": "",
                    "type": "regexp",
                  },
                  "type": "entry",
                },
              ],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`exclude entry regexp 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [
                Object {
                  "name": Object {
                    "content": "tw",
                    "flags": "",
                    "type": "regexp",
                  },
                  "type": "entry",
                },
              ],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`exclude entry string 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [
                Object {
                  "name": Object {
                    "content": "two",
                    "type": "string",
                  },
                  "type": "entry",
                },
              ],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`exclude no exclude 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [
                Object {
                  "name": Object {
                    "content": "foooo",
                    "flags": "",
                    "type": "regexp",
                  },
                  "type": "entry",
                },
              ],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [
                Object {
                  "name": Object {
                    "content": "foooo",
                    "flags": "",
                    "type": "regexp",
                  },
                  "type": "entry",
                },
              ],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of assets is 175 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxAsyncDownloadTime global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxAsyncDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of async assets is 3 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxAsyncDownloadTime not match - global 1`] = `Array []`;

exports[`maxAsyncDownloadTime not match - override global 1`] = `Array []`;

exports[`maxAsyncDownloadTime override global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [
                Object {
                  "limits": Object {
                    "maxAsyncDownloadTime": 1,
                  },
                  "name": Object {
                    "content": ".+",
                    "flags": "",
                    "type": "regexp",
                  },
                },
              ],
              "exclude": Array [],
              "global": Object {
                "maxAsyncDownloadTime": 100000,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of async assets is 3 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxAsyncDownloadTime with useCompressedSize = false 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxAsyncDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": false,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of async assets is 3 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxDownloadTime global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of assets is 175 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxDownloadTime not match - global 1`] = `Array []`;

exports[`maxDownloadTime not match - override global 1`] = `Array []`;

exports[`maxDownloadTime override global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [
                Object {
                  "limits": Object {
                    "maxDownloadTime": 1,
                  },
                  "name": Object {
                    "content": ".+",
                    "flags": "",
                    "type": "regexp",
                  },
                },
              ],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 100000,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [
                Object {
                  "limits": Object {
                    "maxDownloadTime": 1,
                  },
                  "name": Object {
                    "content": ".+",
                    "flags": "",
                    "type": "regexp",
                  },
                },
              ],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 100000,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of assets is 175 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxDownloadTime with useCompressedSize = false 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": false,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of assets is 16 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": false,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of assets is 249 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxInitialDownloadTime global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of initial assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of initial assets is 173 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxInitialDownloadTime not match - global 1`] = `Array []`;

exports[`maxInitialDownloadTime not match - override global 1`] = `Array []`;

exports[`maxInitialDownloadTime override global 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [
                Object {
                  "limits": Object {
                    "maxInitialDownloadTime": 1,
                  },
                  "name": Object {
                    "content": ".+",
                    "flags": "",
                    "type": "regexp",
                  },
                },
              ],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 100000,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of initial assets is 9 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [
                Object {
                  "limits": Object {
                    "maxInitialDownloadTime": 1,
                  },
                  "name": Object {
                    "content": ".+",
                    "flags": "",
                    "type": "regexp",
                  },
                },
              ],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 100000,
              },
              "network": "Slow",
              "useCompressedSize": undefined,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of initial assets is 173 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;

exports[`maxInitialDownloadTime with useCompressedSize = false 1`] = `
Array [
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": false,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"one\\": Download time of initial assets is 16 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "one",
        "type": "entry",
      },
    ],
    "type": "error",
  },
  Object {
    "compilation": "718159f8e48dcecd92c9",
    "details": Array [
      Object {
        "deserialize": Object {
          "content": "
              $theContext: context;
              {
                context: {
                  params: {
                    exclude: $theContext.params.exclude.(deserializeExclude()),
                    byName: $theContext.params.byName.({ name: name.deserializeStringOrRegexp(), limits }),
                    global: $theContext.params.global,
                    network: $theContext.params.network,
                    useCompressedSize: $theContext.params.useCompressedSize,
                  },
                }
              }",
          "type": "query",
        },
        "filename": "input.json",
        "query": "
  $input: resolveInputFile();
  $params: #.params;
  $useCompressedSize: [$params.useCompressedSize, true].useNotNullish();
  $network: [$params.network, 'Slow'].useNotNullish();
  $getSizeByChunks: => files.(getAssetSize($$, $useCompressedSize!=false)).reduce(=> size + $$, 0);
  
  $input.compilations
  .exclude({
    exclude: $params.exclude.[type='compilation'].name,
    get: <name>,
  })
  .({
    $compilation: $;
    $compilation,
    entrypoints: entrypoints
    .exclude({
      exclude: $params.exclude.[type='entry'].name,
      get: <name>,
    })
    .({
      $entry: $;
      $matchedRule: $params.byName.[$entry.name.isMatch(name)].pick(-1).limits;
      $rule: {
        maxDownloadTime: [$matchedRule.maxDownloadTime, $params.global.maxDownloadTime].useNotNullish(),
        maxInitialDownloadTime: [$matchedRule.maxInitialDownloadTime, $params.global.maxInitialDownloadTime].useNotNullish(),
        maxAsyncDownloadTime: [$matchedRule.maxAsyncDownloadTime, $params.global.maxAsyncDownloadTime].useNotNullish(),
      };
      $chunks: ($entry.data.chunks + $entry.data.chunks..children);
      $initialChunks: $chunks.[initial];
      $asyncChunks: $chunks.[not initial];
      $downloadTime: $chunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $initialDownloadTime: $initialChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      $asyncDownloadTime: $asyncChunks.$getSizeByChunks($compilation.hash).getDownloadTime($network);
      
      $entry,
      $chunks,
      $initialChunks,
      $asyncChunks,
      $rule,
      $downloadTime,
      $initialDownloadTime,
      $asyncDownloadTime,
      downloadTimeOK: $rule.maxDownloadTime = null ? true : $downloadTime <= $rule.maxDownloadTime,
      initialDownloadTimeOK: $rule.maxInitialDownloadTime = null ? true : $initialDownloadTime <= $rule.maxInitialDownloadTime,
      asyncDownloadTimeOK: $rule.maxAsyncDownloadTime = null ? true : $asyncDownloadTime <= $rule.maxAsyncDownloadTime,
    })
    .[not (downloadTimeOK and initialDownloadTimeOK and asyncDownloadTimeOK)]
  })
  .[entrypoints]",
        "serialized": Object {
          "context": Object {
            "params": Object {
              "byName": Array [],
              "exclude": Array [],
              "global": Object {
                "maxInitialDownloadTime": 1,
              },
              "network": "Slow",
              "useCompressedSize": false,
            },
          },
        },
        "type": "discovery",
      },
    ],
    "filename": "input.json",
    "message": "Entry \\"two\\": Download time of initial assets is 246 ms. It's over the 1 ms limit",
    "related": Array [
      Object {
        "id": "two",
        "type": "entry",
      },
    ],
    "type": "error",
  },
]
`;
